{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import open3d as o3d\n",
    "import time\n",
    "from scipy.spatial.transform import Rotation as R_scipy\n",
    "import g2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d55a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_associations(filepath):\n",
    "    \"\"\"Reads the associations.txt file.\"\"\"\n",
    "    associations = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 4:\n",
    "                    associations.append((float(parts[0]), parts[1], float(parts[2]), parts[3]))\n",
    "    return associations\n",
    "\n",
    "def read_groundtruth(filepath):\n",
    "    \"\"\"Reads the groundtruth.txt file.\"\"\"\n",
    "    groundtruth = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 8:\n",
    "                    timestamp = float(parts[0])\n",
    "                    pose = np.array(list(map(float, parts[1:])))\n",
    "                    groundtruth[timestamp] = pose\n",
    "    return groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e0788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgbd_frame(dataset_path, rgb_filename, depth_filename):\n",
    "    \"\"\"Loads a synchronized RGB and Depth image pair.\"\"\"\n",
    "    rgb_path = os.path.join(dataset_path, rgb_filename)\n",
    "    depth_path = os.path.join(dataset_path, depth_filename)\n",
    "\n",
    "    rgb_image = cv2.imread(rgb_path, cv2.IMREAD_COLOR)\n",
    "    depth_image_raw = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    if rgb_image is None or depth_image_raw is None:\n",
    "        print(f\"Error loading images: RGB={rgb_path}, Depth={depth_path}\")\n",
    "        return None, None\n",
    "\n",
    "    depth_image_meters = depth_image_raw.astype(np.float32) / 5000.0\n",
    "    depth_image_meters[depth_image_meters == 0] = np.nan\n",
    "\n",
    "    return rgb_image, depth_image_meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae96320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbd_to_point_cloud(rgb_image, depth_image_meters, camera_matrix):\n",
    "    \"\"\"Converts an RGB-D image pair into a colored 3D point cloud.\"\"\"\n",
    "    height, width, _ = rgb_image.shape\n",
    "    fx, fy = camera_matrix[0, 0], camera_matrix[1, 1]\n",
    "    cx, cy = camera_matrix[0, 2], camera_matrix[1, 2]\n",
    "\n",
    "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
    "    u = u.astype(np.float32)\n",
    "    v = v.astype(np.float32)\n",
    "\n",
    "    Z = depth_image_meters.copy()\n",
    "    valid_mask = ~np.isnan(Z)\n",
    "\n",
    "    X = (u - cx) * Z / fx\n",
    "    Y = (v - cy) * Z / fy\n",
    "\n",
    "    points_3d = np.stack((X, Y, Z), axis=-1).reshape(-1, 3)\n",
    "    colors = rgb_image.reshape(-1, 3)\n",
    "\n",
    "    points_3d = points_3d[valid_mask.flatten()]\n",
    "    colors = colors[valid_mask.flatten()]\n",
    "\n",
    "    colors = colors[:, [2, 1, 0]]\n",
    "    return points_3d, colors / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapPoint:\n",
    "    \"\"\"Represents a 3D point in the map.\"\"\"\n",
    "    def __init__(self, id, position_3d):\n",
    "        self.id = id\n",
    "        self.position_3d = np.array(position_3d, dtype=np.float64)\n",
    "        # Observations: {keyframe_id: (feature_idx_in_kf, descriptor)}\n",
    "        # This links which 2D feature in which keyframe observes this 3D map point.\n",
    "        self.observations = {} \n",
    "\n",
    "    def add_observation(self, keyframe_id, feature_idx, descriptor):\n",
    "        self.observations[keyframe_id] = (feature_idx, descriptor)\n",
    "\n",
    "    def get_descriptor(self):\n",
    "        if self.observations:\n",
    "            for obs_data in self.observations.values():\n",
    "                return obs_data[1] \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyFrame:\n",
    "    \"\"\"Represents a keyframe in the map.\"\"\"\n",
    "    def __init__(self, id, timestamp, pose, kps, des, rgb_image_path=None, depth_image_path=None):\n",
    "        self.id = id\n",
    "        self.timestamp = timestamp\n",
    "        self.pose = np.array(pose, dtype=np.float64) # 4x4 SE(3) pose matrix (World_T_Camera)\n",
    "        self.kps = kps # List of cv2.KeyPoint objects\n",
    "        self.des = des # NumPy array of descriptors\n",
    "        # Observed_map_points: {feature_idx_in_kf: map_point_id}\n",
    "        # This links a 2D feature in this keyframe to its observed 3D map point.\n",
    "        self.observed_map_points = {} \n",
    "        self.rgb_image_path = rgb_image_path\n",
    "        self.depth_image_path = depth_image_path\n",
    "\n",
    "    def add_map_point_observation(self, feature_idx, map_point_id):\n",
    "        self.observed_map_points[feature_idx] = map_point_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f683615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    \"\"\"Manages all KeyFrames and MapPoints.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.keyframes = {} # {keyframe_id: KeyFrame_object}\n",
    "        self.map_points = {} # {mappoint_id: MapPoint_object}\n",
    "        self.next_keyframe_id = 0\n",
    "        self.next_mappoint_id = 0\n",
    "\n",
    "    def add_keyframe(self, keyframe_data):\n",
    "        keyframe_id = self.next_keyframe_id\n",
    "        kf = KeyFrame(keyframe_id, **keyframe_data)\n",
    "        self.keyframes[keyframe_id] = kf\n",
    "        self.next_keyframe_id += 1\n",
    "        return kf\n",
    "\n",
    "    def add_mappoint(self, position_3d):\n",
    "        mappoint_id = self.next_mappoint_id\n",
    "        mp = MapPoint(mappoint_id, position_3d)\n",
    "        self.map_points[mappoint_id] = mp\n",
    "        self.next_mappoint_id += 1\n",
    "        return mp\n",
    "\n",
    "    # ...existing code...\n",
    "    def local_bundle_adjustment(self, camera_matrix, current_keyframe_id):\n",
    "        \"\"\"\n",
    "        Bundle Adjustment on a local window of keyframes and their observed map points,\n",
    "        using miquelmassot/g2o-python API.\n",
    "        \"\"\"\n",
    "        if g2o is None:\n",
    "            print(\"g2o-python not installed. Skipping Local Bundle Adjustment.\")\n",
    "            return\n",
    "\n",
    "        print(f\"INFO: Performing Local Bundle Adjustment around KeyFrame {current_keyframe_id}...\")\n",
    "\n",
    "        optimizer = g2o.SparseOptimizer()\n",
    "        solver = g2o.BlockSolverX(g2o.LinearSolverDenseX())\n",
    "        algorithm = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "        optimizer.set_algorithm(algorithm)\n",
    "\n",
    "        fx, fy = camera_matrix[0, 0], camera_matrix[1, 1]\n",
    "        cx, cy = camera_matrix[0, 2], camera_matrix[1, 2]\n",
    "\n",
    "        # Select last 10 keyframes up to current\n",
    "        kf_ids_in_window = sorted([kf_id for kf_id in self.keyframes.keys() if kf_id <= current_keyframe_id])[-10:]\n",
    "        if not kf_ids_in_window:\n",
    "            return\n",
    "\n",
    "        keyframes_to_optimize = [self.keyframes[kf_id] for kf_id in kf_ids_in_window]\n",
    "\n",
    "        # Add keyframe pose vertices\n",
    "        for kf in keyframes_to_optimize:\n",
    "            v_se3 = g2o.VertexSE3Expmap()\n",
    "            v_se3.set_estimate(g2o.SE3Quat(kf.pose[:3, :3], kf.pose[:3, 3]))\n",
    "            v_se3.set_id(kf.id)\n",
    "            optimizer.add_vertex(v_se3)\n",
    "            if kf.id == kf_ids_in_window[0]:\n",
    "                v_se3.set_fixed(True)\n",
    "\n",
    "        # Collect all map points observed in these keyframes\n",
    "        mappoints_to_optimize = set()\n",
    "        for kf in keyframes_to_optimize:\n",
    "            for mp_id in kf.observed_map_points.values():\n",
    "                mappoints_to_optimize.add(mp_id)\n",
    "\n",
    "        # Add map point vertices\n",
    "        for mp_id in mappoints_to_optimize:\n",
    "            mp = self.map_points[mp_id]\n",
    "            v_point = g2o.VertexSBAPointXYZ()\n",
    "            v_point.set_estimate(mp.position_3d)\n",
    "            v_point.set_id(mp.id + 100000)\n",
    "            v_point.set_marginalized(True)\n",
    "            optimizer.add_vertex(v_point)\n",
    "\n",
    "        # Add edges (observations)\n",
    "        for kf in keyframes_to_optimize:\n",
    "            v_se3 = optimizer.vertex(kf.id)\n",
    "            for feat_idx, mp_id in kf.observed_map_points.items():\n",
    "                if mp_id in mappoints_to_optimize:\n",
    "                    mp = self.map_points[mp_id]\n",
    "                    v_point = optimizer.vertex(mp.id + 100000)\n",
    "                    edge = g2o.EdgeProjectXYZ2UV()\n",
    "                    edge.set_vertex(0, v_point)\n",
    "                    edge.set_vertex(1, v_se3)\n",
    "                    observed_uv = kf.kps[feat_idx].pt\n",
    "                    edge.set_measurement(observed_uv)\n",
    "                    edge.set_camera_parameters(fx, fy, cx, cy)\n",
    "                    information_matrix = np.eye(2) * (1.0 / (1.0**2))\n",
    "                    edge.set_information(information_matrix)\n",
    "                    robust_kernel = g2o.RobustKernelHuber()\n",
    "                    robust_kernel.set_delta(1.0)\n",
    "                    edge.set_robust_kernel(robust_kernel)\n",
    "                    optimizer.add_edge(edge)\n",
    "\n",
    "        optimizer.initialize_optimization()\n",
    "        optimizer.optimize(20)\n",
    "\n",
    "        # Update keyframes\n",
    "        for kf_id in kf_ids_in_window:\n",
    "            v_se3 = optimizer.vertex(kf_id)\n",
    "            if v_se3:\n",
    "                optimized_pose_quat = v_se3.estimate()\n",
    "                optimized_pose = optimized_pose_quat.matrix()\n",
    "                self.keyframes[kf_id].pose = optimized_pose\n",
    "\n",
    "        # Update map points\n",
    "        for mp_id in mappoints_to_optimize:\n",
    "            v_point = optimizer.vertex(mp_id + 100000)\n",
    "            if v_point:\n",
    "                optimized_position = v_point.estimate()\n",
    "                self.map_points[mp_id].position_3d = optimized_position\n",
    "\n",
    "        print(f\"INFO: Local BA completed. Optimized {len(kf_ids_in_window)} KeyFrames and {len(mappoints_to_optimize)} MapPoints.\")\n",
    "    # ...existing code...\n",
    "\n",
    "    def global_bundle_adjustment(self, camera_matrix):\n",
    "        \"\"\"\n",
    "        Conceptual placeholder for Global Bundle Adjustment.\n",
    "        Similar to local BA but operates on all keyframes and map points.\n",
    "        \"\"\"\n",
    "        if g2o is None:\n",
    "            print(\"g2o-python not installed. Skipping Global Bundle Adjustment.\")\n",
    "            return\n",
    "        print(\"INFO: Performing Global Bundle Adjustment (Conceptual)...\")\n",
    "        # Full implementation would be similar to local_bundle_adjustment\n",
    "        # but iterating over all keyframes and map points in self.keyframes/self.map_points\n",
    "        # and would typically be very slow.\n",
    "        pass\n",
    "\n",
    "    def pose_graph_optimization(self, loop_constraint_kf_id, loop_constraint_transform):\n",
    "        \"\"\"\n",
    "        Optimizes the pose graph after a loop closure is detected,\n",
    "        using miquelmassot/g2o-python API.\n",
    "        `loop_constraint_transform` should be the 4x4 relative transformation\n",
    "        (e.g., T_current_kf_loop_kf) between the current keyframe and the detected loop keyframe.\n",
    "        \"\"\"\n",
    "        if g2o is None:\n",
    "            print(\"g2o-python not installed. Skipping Pose Graph Optimization.\")\n",
    "            return\n",
    "\n",
    "        print(\"INFO: Performing Pose Graph Optimization...\")\n",
    "\n",
    "        optimizer = g2o.SparseOptimizer()\n",
    "        # Use BlockSolverSE3 for SE3 vertices/edges in PGO\n",
    "        solver = g2o.BlockSolverSE3(g2o.LinearSolverDenseSE3()) # LinearSolverDenseSE3 for 6x6 blocks\n",
    "        algorithm = g2o.OptimizationAlgorithmLevenberg(solver)\n",
    "        optimizer.set_algorithm(algorithm)\n",
    "\n",
    "        # Add all Keyframe Poses as Vertices (VertexSE3)\n",
    "        for kf_id, kf in self.keyframes.items():\n",
    "            v_se3 = g2o.VertexSE3() # VertexSE3 is fine for PGO (not BA, which uses Expmap)\n",
    "            v_se3.set_id(kf.id)\n",
    "            v_se3.set_estimate(g2o.SE3Quat(kf.pose[:3,:3], kf.pose[:3,3]))\n",
    "            optimizer.add_vertex(v_se3)\n",
    "\n",
    "            # Fix the first keyframe to anchor the graph\n",
    "            if kf.id == 0:\n",
    "                v_se3.set_fixed(True)\n",
    "\n",
    "        # Add Odometry Edges (relative transformations between consecutive KeyFrames)\n",
    "        kf_ids_sorted = sorted(self.keyframes.keys())\n",
    "        for i in range(len(kf_ids_sorted) - 1):\n",
    "            kf1_id = kf_ids_sorted[i]\n",
    "            kf2_id = kf_ids_sorted[i+1]\n",
    "            kf1 = self.keyframes[kf1_id]\n",
    "            kf2 = self.keyframes[kf2_id]\n",
    "\n",
    "            # Relative transform from kf1 to kf2: T_kf1_kf2 = T_kf1_W @ T_W_kf2 = inv(T_W_kf1) @ T_W_kf2\n",
    "            T_kf1_kf2 = np.linalg.inv(kf1.pose) @ kf2.pose\n",
    "\n",
    "            edge = g2o.EdgeSE3() # EdgeSE3 for 6D pose constraints\n",
    "            edge.set_vertex(0, optimizer.vertex(kf1_id))\n",
    "            edge.set_vertex(1, optimizer.vertex(kf2_id))\n",
    "            edge.set_measurement(g2o.SE3Quat(T_kf1_kf2[:3,:3], T_kf1_kf2[:3,3]))\n",
    "            # Information matrix for odometry (high confidence)\n",
    "            edge.set_information(np.eye(6) * 100.0) # Example: High confidence\n",
    "            optimizer.add_edge(edge)\n",
    "\n",
    "        # Add the Loop Closure Edge\n",
    "        current_kf = self.keyframes.get(self.next_keyframe_id -1) # Latest keyframe\n",
    "        loop_kf = self.keyframes.get(loop_constraint_kf_id) # The keyframe we looped to\n",
    "\n",
    "        if current_kf and loop_kf and loop_constraint_transform is not None:\n",
    "            loop_edge = g2o.EdgeSE3()\n",
    "            loop_edge.set_vertex(0, optimizer.vertex(loop_kf.id)) # Loop Keyframe\n",
    "            loop_edge.set_vertex(1, optimizer.vertex(current_kf.id)) # Current Keyframe\n",
    "            loop_edge.set_measurement(g2o.SE3Quat(loop_constraint_transform[:3,:3], loop_constraint_transform[:3,3]))\n",
    "            # Information matrix for loop closure (usually lower confidence than odometry, but critical)\n",
    "            loop_edge.set_information(np.eye(6) * 10.0) # Example: Medium confidence\n",
    "            optimizer.add_edge(loop_edge)\n",
    "            print(f\"Added loop closure edge between KF {loop_kf.id} and KF {current_kf.id}.\")\n",
    "\n",
    "        # Perform Optimization\n",
    "        optimizer.initialize_optimization()\n",
    "        optimizer.optimize(50) # More iterations for global optimization\n",
    "\n",
    "        # Update Map with Optimized Values\n",
    "        for kf_id, kf in self.keyframes.items():\n",
    "            v_se3 = optimizer.vertex(kf_id)\n",
    "            if v_se3:\n",
    "                optimized_pose_quat = v_se3.estimate()\n",
    "                optimized_pose = optimized_pose_quat.matrix()\n",
    "                kf.pose = optimized_pose\n",
    "        \n",
    "        print(\"INFO: Pose Graph Optimization completed.\")\n",
    "        # After PGO, you would typically trigger a Global Bundle Adjustment\n",
    "        # or re-triangulate/refine map points based on the new keyframe poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58016230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ORBSLAMSystem:\n",
    "    def __init__(self, camera_matrix, dist_coeffs):\n",
    "        self.camera_matrix = camera_matrix\n",
    "        self.dist_coeffs = dist_coeffs\n",
    "\n",
    "        self.orb = cv2.ORB_create(nfeatures=2000, scaleFactor=1.2, nlevels=8)\n",
    "        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "        self.map = Map() # Central map object\n",
    "        self.current_estimated_pose = np.eye(4) # Initial pose (World_T_Camera)\n",
    "        self.estimated_trajectory_poses = [] # List of 4x4 poses\n",
    "\n",
    "        self.last_frame_kps = None\n",
    "        self.last_frame_des = None\n",
    "        self.last_keyframe = None # Reference to the last added KeyFrame object\n",
    "\n",
    "        self.frame_count = 0\n",
    "\n",
    "    def process_frame(self, timestamp, rgb_image, depth_image_meters):\n",
    "        self.frame_count += 1\n",
    "        rgb_image_processed = rgb_image.copy()\n",
    "        rgb_image_gray = cv2.cvtColor(rgb_image_processed, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        current_kps, current_des = self.orb.detectAndCompute(rgb_image_gray, None)\n",
    "\n",
    "        if current_des is None or len(current_kps) < 5:\n",
    "            print(f\"Warning: Not enough features detected ({len(current_kps)}). Skipping pose estimation.\")\n",
    "            if len(self.estimated_trajectory_poses) > 0:\n",
    "                self.estimated_trajectory_poses.append(self.current_estimated_pose)\n",
    "            return self.current_estimated_pose, self._get_current_map_point_cloud()\n",
    "\n",
    "        if self.last_keyframe is None: # First frame initialization\n",
    "            self.current_estimated_pose = np.eye(4) # Start at origin\n",
    "            self.estimated_trajectory_poses.append(self.current_estimated_pose)\n",
    "\n",
    "            # Add initial keyframe to map\n",
    "            self.last_keyframe = self.map.add_keyframe({\n",
    "                'timestamp': timestamp,\n",
    "                'pose': self.current_estimated_pose,\n",
    "                'kps': current_kps,\n",
    "                'des': current_des,\n",
    "            })\n",
    "\n",
    "            # Initialize map points from the first keyframe using depth\n",
    "            points_3d, colors = rgbd_to_point_cloud(rgb_image_processed, depth_image_meters, self.camera_matrix)\n",
    "            \n",
    "            # --- IMPORTANT: Associate 2D features with 3D MapPoints during initialization ---\n",
    "            # This part needs to be robustly implemented for real BA!\n",
    "            # For simplicity, we create a MapPoint for each valid 3D point and associate it with\n",
    "            # the corresponding 2D feature IF a feature exists at that pixel location,\n",
    "            # or simply with a feature by index for demonstration.\n",
    "            # In a real system:\n",
    "            # 1. Project 3D points from depth map to 2D.\n",
    "            # 2. Find ORB features close to these projected points.\n",
    "            # 3. Create MapPoints only for those ORB features that have valid depth.\n",
    "            \n",
    "            # A more robust initialization would use PnP or Bundle Adjustment on initial frames.\n",
    "            # Here, we'll try a basic association for existing kps that 'fall into' valid 3D points\n",
    "            \n",
    "            # Create a KD-tree or similar for efficient nearest neighbor search if many kps\n",
    "            kp_coords_2d = np.array([kp.pt for kp in current_kps])\n",
    "            \n",
    "            # Instead of iterating through all 3D points, let's iterate through detected features\n",
    "            # and find their 3D point from depth map (if available).\n",
    "            for feat_idx, kp in enumerate(current_kps):\n",
    "                u, v = int(round(kp.pt[0])), int(round(kp.pt[1]))\n",
    "                if 0 <= v < depth_image_meters.shape[0] and 0 <= u < depth_image_meters.shape[1]:\n",
    "                    depth_val = depth_image_meters[v, u]\n",
    "                    if not np.isnan(depth_val) and depth_val > 0:\n",
    "                        # Convert 2D point (u,v) with depth to 3D point in camera frame\n",
    "                        X_c = (u - self.camera_matrix[0, 2]) * depth_val / self.camera_matrix[0, 0]\n",
    "                        Y_c = (v - self.camera_matrix[1, 2]) * depth_val / self.camera_matrix[1, 1]\n",
    "                        Z_c = depth_val\n",
    "                        \n",
    "                        p3d_camera_frame = np.array([X_c, Y_c, Z_c, 1.0])\n",
    "                        # Transform to world frame (assuming current_estimated_pose is identity for first frame)\n",
    "                        p3d_world = self.current_estimated_pose @ p3d_camera_frame\n",
    "                        p3d_world = p3d_world[:3] # Convert homogeneous to 3D\n",
    "\n",
    "                        mp = self.map.add_mappoint(p3d_world)\n",
    "                        descriptor = current_des[feat_idx] if current_des is not None else None\n",
    "                        mp.add_observation(self.last_keyframe.id, feat_idx, descriptor)\n",
    "                        self.last_keyframe.add_map_point_observation(feat_idx, mp.id)\n",
    "\n",
    "            print(f\"Initialized with {len(self.map.map_points)} map points and KeyFrame {self.last_keyframe.id}.\")\n",
    "\n",
    "            self.last_frame_kps = current_kps\n",
    "            self.last_frame_des = current_des\n",
    "            return self.current_estimated_pose, self._get_current_map_point_cloud()\n",
    "\n",
    "        # Tracking: Match features with last frame\n",
    "        if self.last_frame_des is None or current_des.dtype != self.last_frame_des.dtype:\n",
    "            print(\"Descriptor type mismatch or last_frame_des is None. Resetting tracking.\")\n",
    "            self.last_frame_kps = current_kps\n",
    "            self.last_frame_des = current_des\n",
    "            if len(self.estimated_trajectory_poses) > 0:\n",
    "                self.estimated_trajectory_poses.append(self.current_estimated_pose)\n",
    "            return self.current_estimated_pose, self._get_current_map_point_cloud()\n",
    "\n",
    "        matches = self.bf.match(current_des, self.last_frame_des)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        good_matches = matches[:200]\n",
    "\n",
    "        if len(good_matches) < 8:\n",
    "            print(f\"Warning: Not enough good matches ({len(good_matches)}) for pose estimation. Using last pose.\")\n",
    "            self.estimated_trajectory_poses.append(self.current_estimated_pose)\n",
    "            self.last_frame_kps = current_kps\n",
    "            self.last_frame_des = current_des\n",
    "            return self.current_estimated_pose, self._get_current_map_point_cloud()\n",
    "\n",
    "        pts_curr = np.float32([current_kps[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        pts_prev = np.float32([self.last_frame_kps[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        E, mask = cv2.findEssentialMat(pts_curr, pts_prev, self.camera_matrix, method=cv2.RANSAC, prob=0.999, threshold=1.0)\n",
    "        _, R_prev_curr, t_prev_curr, mask_RP = cv2.recoverPose(E, pts_curr, pts_prev, self.camera_matrix, mask=mask)\n",
    "\n",
    "        T_prev_curr = np.eye(4)\n",
    "        T_prev_curr[:3, :3] = R_prev_curr\n",
    "        T_prev_curr[:3, 3] = t_prev_curr.flatten()\n",
    "\n",
    "        T_C_prev_C_curr = np.linalg.inv(T_prev_curr) # Transformation from previous to current camera\n",
    "        self.current_estimated_pose = self.current_estimated_pose @ T_C_prev_C_curr\n",
    "        self.estimated_trajectory_poses.append(self.current_estimated_pose)\n",
    "\n",
    "        # Keyframe Management and Map Point Triangulation\n",
    "        translation_diff = np.linalg.norm(self.current_estimated_pose[:3, 3] - self.last_keyframe.pose[:3, 3])\n",
    "        \n",
    "        is_keyframe = False\n",
    "        if translation_diff > 0.15 or (self.frame_count % 30 == 0 and len(self.map.keyframes) > 1):\n",
    "            is_keyframe = True\n",
    "            \n",
    "            new_keyframe = self.map.add_keyframe({\n",
    "                'timestamp': timestamp,\n",
    "                'pose': self.current_estimated_pose,\n",
    "                'kps': current_kps,\n",
    "                'des': current_des,\n",
    "            })\n",
    "            print(f\"Added new KeyFrame {new_keyframe.id} at frame {self.frame_count}.\")\n",
    "\n",
    "            good_matches_inliers = [m for m, mask_val in zip(good_matches, mask_RP.flatten()) if mask_val == 1]\n",
    "            \n",
    "            if len(good_matches_inliers) >= 8:\n",
    "                pts_kf1_matched = np.float32([self.last_keyframe.kps[m.trainIdx].pt for m in good_matches_inliers]).reshape(-1, 2)\n",
    "                pts_kf2_matched = np.float32([current_kps[m.queryIdx].pt for m in good_matches_inliers]).reshape(-1, 2)\n",
    "\n",
    "                P_kf1 = self.camera_matrix @ self.last_keyframe.pose[:3, :]\n",
    "                P_curr = self.camera_matrix @ new_keyframe.pose[:3, :]\n",
    "\n",
    "                points_4d_hom = cv2.triangulatePoints(P_kf1, P_curr, pts_kf1_matched.T, pts_kf2_matched.T)\n",
    "                points_3d_new_world = (points_4d_hom / points_4d_hom[3]).T[:, :3]\n",
    "\n",
    "                valid_triangulation_mask = (points_3d_new_world[:, 2] > 0) # Basic depth filter (positive Z)\n",
    "                points_3d_new_world = points_3d_new_world[valid_triangulation_mask]\n",
    "\n",
    "                # --- IMPORTANT: Associate 2D features with new 3D MapPoints ---\n",
    "                valid_matches_for_new_points = [m for m, valid in zip(good_matches_inliers, valid_triangulation_mask) if valid]\n",
    "\n",
    "                if points_3d_new_world.shape[0] > 0:\n",
    "                    for j, p3d in enumerate(points_3d_new_world):\n",
    "                        match_info = valid_matches_for_new_points[j]\n",
    "                        \n",
    "                        mp = self.map.add_mappoint(p3d)\n",
    "                        \n",
    "                        # Add observation from the previous keyframe (trainer of the match)\n",
    "                        mp_descriptor = self.last_keyframe.des[match_info.trainIdx] if self.last_keyframe.des is not None else None\n",
    "                        mp.add_observation(self.last_keyframe.id, match_info.trainIdx, mp_descriptor)\n",
    "                        self.last_keyframe.add_map_point_observation(match_info.trainIdx, mp.id)\n",
    "\n",
    "                        # Add observation from the current keyframe (query of the match)\n",
    "                        mp_descriptor_curr = new_keyframe.des[match_info.queryIdx] if new_keyframe.des is not None else None\n",
    "                        mp.add_observation(new_keyframe.id, match_info.queryIdx, mp_descriptor_curr)\n",
    "                        new_keyframe.add_map_point_observation(match_info.queryIdx, mp.id)\n",
    "                        \n",
    "                    print(f\"Triangulated {points_3d_new_world.shape[0]} new map points and linked observations.\")\n",
    "\n",
    "            # --- LOCAL BUNDLE ADJUSTMENT ---\n",
    "            self.map.local_bundle_adjustment(self.camera_matrix, new_keyframe.id)\n",
    "\n",
    "            # --- LOOP CLOSURE (Conceptual Placeholder) ---\n",
    "            # Simulate a detected loop every N frames and trigger PGO.\n",
    "            if new_keyframe.id > 0 and new_keyframe.id % 10 == 0: # Example: Check every 10th keyframe\n",
    "                # In a real system:\n",
    "                # 1. Place Recognition: Use DBoW2 or similar to find a loop candidate (e.g., matching KF 0)\n",
    "                # 2. Geometric Verification: Verify the loop geometrically (e.g., with RANSAC-based PnP)\n",
    "                # 3. If verified, obtain the relative transformation (T_current_kf_loop_kf)\n",
    "                \n",
    "                # Simulating a loop to KF 0 (first keyframe)\n",
    "                print(f\"Simulating loop closure: KF {new_keyframe.id} potentially loops to KF 0.\")\n",
    "                if len(self.map.keyframes) > 0:\n",
    "                    loop_kf_id = 0 # Assume we loop back to the very first keyframe for simulation\n",
    "                    loop_kf_obj = self.map.keyframes.get(loop_kf_id)\n",
    "                    if loop_kf_obj:\n",
    "                        # T_current_kf_loop_kf = inv(T_W_curr_kf) @ T_W_loop_kf\n",
    "                        simulated_loop_transform = np.linalg.inv(new_keyframe.pose) @ loop_kf_obj.pose\n",
    "                        \n",
    "                        self.map.pose_graph_optimization(loop_kf_id, simulated_loop_transform)\n",
    "                        # After PGO, it's common to run a Global BA to further refine the map\n",
    "                        # self.map.global_bundle_adjustment(self.camera_matrix)\n",
    "                    else:\n",
    "                        print(f\"Simulated loop target KeyFrame {loop_kf_id} not found.\")\n",
    "            \n",
    "            self.last_keyframe = new_keyframe\n",
    "\n",
    "        self.last_frame_kps = current_kps\n",
    "        self.last_frame_des = current_des\n",
    "\n",
    "        return self.current_estimated_pose, self._get_current_map_point_cloud()\n",
    "\n",
    "    def _get_current_map_point_cloud(self):\n",
    "        \"\"\"Generates an Open3D PointCloud from the current MapPoints.\"\"\"\n",
    "        points = []\n",
    "        colors = []\n",
    "        if self.map.map_points:\n",
    "            for mp_id, mp in self.map.map_points.items():\n",
    "                points.append(mp.position_3d)\n",
    "                colors.append([0.0, 0.7, 1.0]) # Light blue for map points\n",
    "        \n",
    "        o3d_pc = o3d.geometry.PointCloud()\n",
    "        if points:\n",
    "            o3d_pc.points = o3d.utility.Vector3dVector(np.array(points))\n",
    "            o3d_pc.colors = o3d.utility.Vector3dVector(np.array(colors))\n",
    "        return o3d_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef3fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = 525.0\n",
    "fy = 525.0\n",
    "cx = 319.5\n",
    "cy = 239.5\n",
    "k1 = 0.0  # Example value, adjust if needed\n",
    "k2 = 0.0  # Example value, adjust if needed\n",
    "p1 = 0.0  # Example value, adjust if needed\n",
    "p2 = 0.0  # Example value, adjust if needed\n",
    "k3 = 0.0  # Example value, adjust if needed\n",
    "\n",
    "camera_matrix = np.array([[fx, 0, cx],\n",
    "                          [0, fy, cy],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "dist_coeffs = np.array([k1, k2, p1, p2, k3], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c83d50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2488 associated RGB-D frames.\n",
      "Loaded 8710 ground truth poses.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r'rgbd_dataset_freiburg3_long_office_household' # Replace with your actual path!\n",
    "associations_file = os.path.join(dataset_path, 'associations.txt')\n",
    "groundtruth_file = os.path.join(dataset_path, 'groundtruth.txt')\n",
    "\n",
    "associations = read_associations(associations_file)\n",
    "groundtruth_poses = read_groundtruth(groundtruth_file)\n",
    "\n",
    "print(f\"Loaded {len(associations)} associated RGB-D frames.\")\n",
    "print(f\"Loaded {len(groundtruth_poses)} ground truth poses.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n",
      "Processing frame 0...\n",
      "Processing frame 10...\n",
      "Processing frame 20...\n",
      "Processing frame 30...\n",
      "Triangulated 36 new map points.\n",
      "Processing frame 40...\n",
      "Triangulated 188 new map points.\n",
      "Processing frame 50...\n",
      "Triangulated 17 new map points.\n",
      "Processing frame 60...\n",
      "Triangulated 28 new map points.\n",
      "Processing frame 70...\n",
      "Triangulated 115 new map points.\n",
      "Processing frame 80...\n",
      "Triangulated 188 new map points.\n",
      "Processing frame 90...\n",
      "Triangulated 157 new map points.\n",
      "Processing frame 100...\n",
      "Triangulated 121 new map points.\n",
      "Processing frame 110...\n",
      "Triangulated 71 new map points.\n",
      "Processing frame 120...\n",
      "Triangulated 175 new map points.\n",
      "Processing frame 130...\n",
      "Triangulated 165 new map points.\n",
      "Processing frame 140...\n",
      "Triangulated 182 new map points.\n",
      "Processing frame 150...\n",
      "Triangulated 176 new map points.\n",
      "Processing frame 160...\n",
      "Triangulated 180 new map points.\n",
      "Processing frame 170...\n",
      "Triangulated 167 new map points.\n",
      "Processing frame 180...\n",
      "Triangulated 156 new map points.\n",
      "Processing frame 190...\n",
      "Triangulated 139 new map points.\n",
      "Processing frame 200...\n",
      "Triangulated 171 new map points.\n",
      "Processing frame 210...\n",
      "Triangulated 148 new map points.\n",
      "Processing frame 220...\n",
      "Triangulated 176 new map points.\n",
      "Processing frame 230...\n",
      "Triangulated 180 new map points.\n",
      "Processing frame 240...\n",
      "Triangulated 175 new map points.\n",
      "Processing frame 250...\n",
      "Triangulated 69 new map points.\n",
      "Processing frame 260...\n",
      "Triangulated 109 new map points.\n",
      "Processing frame 270...\n",
      "Triangulated 126 new map points.\n",
      "Processing frame 280...\n",
      "Triangulated 82 new map points.\n",
      "Processing frame 290...\n",
      "Triangulated 149 new map points.\n",
      "Processing frame 300...\n",
      "Triangulated 113 new map points.\n",
      "Processing frame 310...\n",
      "Triangulated 161 new map points.\n",
      "Processing frame 320...\n",
      "Triangulated 9 new map points.\n",
      "Processing frame 330...\n",
      "Triangulated 105 new map points.\n",
      "Processing frame 340...\n",
      "Triangulated 174 new map points.\n",
      "Processing frame 350...\n",
      "Triangulated 104 new map points.\n",
      "Processing frame 360...\n",
      "Triangulated 168 new map points.\n",
      "Processing frame 370...\n",
      "Triangulated 81 new map points.\n",
      "Processing frame 380...\n",
      "Triangulated 149 new map points.\n",
      "Processing frame 390...\n",
      "Triangulated 144 new map points.\n",
      "Processing frame 400...\n",
      "Triangulated 110 new map points.\n",
      "Processing frame 410...\n",
      "Triangulated 160 new map points.\n",
      "Processing frame 420...\n",
      "Triangulated 156 new map points.\n",
      "Processing frame 430...\n",
      "Triangulated 153 new map points.\n",
      "Processing frame 440...\n",
      "Triangulated 87 new map points.\n",
      "Processing frame 450...\n",
      "Triangulated 112 new map points.\n",
      "Processing frame 460...\n",
      "Triangulated 42 new map points.\n",
      "Processing frame 470...\n",
      "Triangulated 105 new map points.\n",
      "Processing frame 480...\n",
      "Triangulated 152 new map points.\n",
      "Processing frame 490...\n",
      "Triangulated 36 new map points.\n",
      "Processing frame 500...\n",
      "Triangulated 114 new map points.\n",
      "Processing frame 510...\n",
      "Triangulated 131 new map points.\n",
      "Processing frame 520...\n",
      "Triangulated 180 new map points.\n",
      "Processing frame 530...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 540...\n",
      "Triangulated 174 new map points.\n",
      "Processing frame 550...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 560...\n",
      "Triangulated 124 new map points.\n",
      "Processing frame 570...\n",
      "Triangulated 142 new map points.\n",
      "Processing frame 580...\n",
      "Triangulated 157 new map points.\n",
      "Processing frame 590...\n",
      "Triangulated 123 new map points.\n",
      "Processing frame 600...\n",
      "Triangulated 49 new map points.\n",
      "Processing frame 610...\n",
      "Triangulated 118 new map points.\n",
      "Processing frame 620...\n",
      "Triangulated 117 new map points.\n",
      "Processing frame 630...\n",
      "Triangulated 148 new map points.\n",
      "Processing frame 640...\n",
      "Triangulated 133 new map points.\n",
      "Processing frame 650...\n",
      "Triangulated 129 new map points.\n",
      "Processing frame 660...\n",
      "Triangulated 170 new map points.\n",
      "Processing frame 670...\n",
      "Triangulated 157 new map points.\n",
      "Processing frame 680...\n",
      "Triangulated 121 new map points.\n",
      "Processing frame 690...\n",
      "Triangulated 154 new map points.\n",
      "Processing frame 700...\n",
      "Triangulated 163 new map points.\n",
      "Processing frame 710...\n",
      "Triangulated 186 new map points.\n",
      "Processing frame 720...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 730...\n",
      "Triangulated 123 new map points.\n",
      "Processing frame 740...\n",
      "Triangulated 118 new map points.\n",
      "Processing frame 750...\n",
      "Triangulated 39 new map points.\n",
      "Processing frame 760...\n",
      "Triangulated 157 new map points.\n",
      "Processing frame 770...\n",
      "Triangulated 25 new map points.\n",
      "Processing frame 780...\n",
      "Triangulated 172 new map points.\n",
      "Processing frame 790...\n",
      "Triangulated 175 new map points.\n",
      "Processing frame 800...\n",
      "Triangulated 185 new map points.\n",
      "Processing frame 810...\n",
      "Triangulated 168 new map points.\n",
      "Processing frame 820...\n",
      "Triangulated 117 new map points.\n",
      "Processing frame 830...\n",
      "Triangulated 179 new map points.\n",
      "Processing frame 840...\n",
      "Triangulated 181 new map points.\n",
      "Processing frame 850...\n",
      "Triangulated 82 new map points.\n",
      "Processing frame 860...\n",
      "Triangulated 7 new map points.\n",
      "Processing frame 870...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 880...\n",
      "Triangulated 94 new map points.\n",
      "Processing frame 890...\n",
      "Triangulated 105 new map points.\n",
      "Processing frame 900...\n",
      "Triangulated 105 new map points.\n",
      "Processing frame 910...\n",
      "Triangulated 152 new map points.\n",
      "Processing frame 920...\n",
      "Triangulated 109 new map points.\n",
      "Processing frame 930...\n",
      "Triangulated 117 new map points.\n",
      "Processing frame 940...\n",
      "Triangulated 113 new map points.\n",
      "Processing frame 950...\n",
      "Triangulated 152 new map points.\n",
      "Processing frame 960...\n",
      "Triangulated 130 new map points.\n",
      "Processing frame 970...\n",
      "Triangulated 96 new map points.\n",
      "Processing frame 980...\n",
      "Triangulated 60 new map points.\n",
      "Processing frame 990...\n",
      "Triangulated 28 new map points.\n",
      "Processing frame 1000...\n",
      "Processing frame 1010...\n",
      "Triangulated 40 new map points.\n",
      "Processing frame 1020...\n",
      "Triangulated 42 new map points.\n",
      "Processing frame 1030...\n",
      "Triangulated 94 new map points.\n",
      "Processing frame 1040...\n",
      "Triangulated 77 new map points.\n",
      "Processing frame 1050...\n",
      "Triangulated 143 new map points.\n",
      "Processing frame 1060...\n",
      "Triangulated 32 new map points.\n",
      "Processing frame 1070...\n",
      "Triangulated 24 new map points.\n",
      "Processing frame 1080...\n",
      "Triangulated 163 new map points.\n",
      "Processing frame 1090...\n",
      "Triangulated 116 new map points.\n",
      "Processing frame 1100...\n",
      "Triangulated 127 new map points.\n",
      "Processing frame 1110...\n",
      "Triangulated 47 new map points.\n",
      "Processing frame 1120...\n",
      "Triangulated 158 new map points.\n",
      "Processing frame 1130...\n",
      "Triangulated 71 new map points.\n",
      "Processing frame 1140...\n",
      "Triangulated 62 new map points.\n",
      "Processing frame 1150...\n",
      "Triangulated 115 new map points.\n",
      "Processing frame 1160...\n",
      "Triangulated 118 new map points.\n",
      "Processing frame 1170...\n",
      "Triangulated 62 new map points.\n",
      "Processing frame 1180...\n",
      "Triangulated 56 new map points.\n",
      "Processing frame 1190...\n",
      "Triangulated 70 new map points.\n",
      "Processing frame 1200...\n",
      "Triangulated 73 new map points.\n",
      "Processing frame 1210...\n",
      "Triangulated 57 new map points.\n",
      "Processing frame 1220...\n",
      "Triangulated 140 new map points.\n",
      "Processing frame 1230...\n",
      "Triangulated 113 new map points.\n",
      "Processing frame 1240...\n",
      "Triangulated 137 new map points.\n",
      "Processing frame 1250...\n",
      "Triangulated 137 new map points.\n",
      "Processing frame 1260...\n",
      "Triangulated 137 new map points.\n",
      "Processing frame 1270...\n",
      "Triangulated 11 new map points.\n",
      "Processing frame 1280...\n",
      "Triangulated 28 new map points.\n",
      "Processing frame 1290...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 1300...\n",
      "Triangulated 127 new map points.\n",
      "Processing frame 1310...\n",
      "Triangulated 12 new map points.\n",
      "Processing frame 1320...\n",
      "Triangulated 178 new map points.\n",
      "Processing frame 1330...\n",
      "Triangulated 157 new map points.\n",
      "Processing frame 1340...\n",
      "Triangulated 157 new map points.\n",
      "Processing frame 1350...\n",
      "Triangulated 167 new map points.\n",
      "Processing frame 1360...\n",
      "Triangulated 168 new map points.\n",
      "Processing frame 1370...\n",
      "Triangulated 154 new map points.\n",
      "Processing frame 1380...\n",
      "Triangulated 174 new map points.\n",
      "Processing frame 1390...\n",
      "Triangulated 151 new map points.\n",
      "Processing frame 1400...\n",
      "Triangulated 170 new map points.\n",
      "Processing frame 1410...\n",
      "Triangulated 161 new map points.\n",
      "Processing frame 1420...\n",
      "Triangulated 150 new map points.\n",
      "Processing frame 1430...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 1440...\n",
      "Triangulated 154 new map points.\n",
      "Processing frame 1450...\n",
      "Triangulated 164 new map points.\n",
      "Processing frame 1460...\n",
      "Triangulated 123 new map points.\n",
      "Processing frame 1470...\n",
      "Triangulated 138 new map points.\n",
      "Processing frame 1480...\n",
      "Triangulated 119 new map points.\n",
      "Processing frame 1490...\n",
      "Triangulated 172 new map points.\n",
      "Processing frame 1500...\n",
      "Triangulated 186 new map points.\n",
      "Processing frame 1510...\n",
      "Triangulated 120 new map points.\n",
      "Processing frame 1520...\n",
      "Triangulated 165 new map points.\n",
      "Processing frame 1530...\n",
      "Triangulated 48 new map points.\n",
      "Processing frame 1540...\n",
      "Triangulated 60 new map points.\n",
      "Processing frame 1550...\n",
      "Triangulated 172 new map points.\n",
      "Processing frame 1560...\n",
      "Triangulated 166 new map points.\n",
      "Processing frame 1570...\n",
      "Triangulated 169 new map points.\n",
      "Processing frame 1580...\n",
      "Triangulated 27 new map points.\n",
      "Processing frame 1590...\n",
      "Triangulated 175 new map points.\n",
      "Processing frame 1600...\n",
      "Triangulated 185 new map points.\n",
      "Processing frame 1610...\n",
      "Triangulated 163 new map points.\n",
      "Processing frame 1620...\n",
      "Triangulated 176 new map points.\n",
      "Processing frame 1630...\n",
      "Triangulated 147 new map points.\n",
      "Processing frame 1640...\n",
      "Triangulated 108 new map points.\n",
      "Processing frame 1650...\n",
      "Triangulated 135 new map points.\n",
      "Processing frame 1660...\n",
      "Triangulated 87 new map points.\n",
      "Processing frame 1670...\n",
      "Triangulated 113 new map points.\n",
      "Processing frame 1680...\n",
      "Triangulated 129 new map points.\n",
      "Processing frame 1690...\n",
      "Triangulated 37 new map points.\n",
      "Processing frame 1700...\n",
      "Triangulated 15 new map points.\n",
      "Processing frame 1710...\n",
      "Triangulated 1 new map points.\n",
      "Processing frame 1720...\n",
      "Triangulated 42 new map points.\n",
      "Processing frame 1730...\n",
      "Triangulated 46 new map points.\n",
      "Processing frame 1740...\n",
      "Triangulated 89 new map points.\n",
      "Processing frame 1750...\n",
      "Triangulated 102 new map points.\n",
      "Processing frame 1760...\n",
      "Triangulated 112 new map points.\n",
      "Processing frame 1770...\n",
      "Processing frame 1780...\n",
      "Triangulated 109 new map points.\n",
      "Processing frame 1790...\n",
      "Triangulated 78 new map points.\n",
      "Processing frame 1800...\n",
      "Triangulated 73 new map points.\n",
      "Processing frame 1810...\n",
      "Processing frame 1820...\n",
      "Triangulated 158 new map points.\n",
      "Processing frame 1830...\n",
      "Triangulated 150 new map points.\n",
      "Processing frame 1840...\n",
      "Processing frame 1850...\n",
      "Processing frame 1860...\n",
      "Processing frame 1870...\n",
      "Processing frame 1880...\n",
      "Processing frame 1890...\n",
      "Processing frame 1900...\n",
      "Processing frame 1910...\n",
      "Processing frame 1920...\n",
      "Processing frame 1930...\n",
      "Triangulated 84 new map points.\n",
      "Processing frame 1940...\n",
      "Triangulated 64 new map points.\n",
      "Processing frame 1950...\n",
      "Processing frame 1960...\n",
      "Triangulated 110 new map points.\n",
      "Processing frame 1970...\n",
      "Triangulated 5 new map points.\n",
      "Processing frame 1980...\n",
      "Triangulated 154 new map points.\n",
      "Processing frame 1990...\n",
      "Processing frame 2000...\n",
      "Processing frame 2010...\n",
      "Processing frame 2020...\n",
      "Processing frame 2030...\n",
      "Triangulated 79 new map points.\n",
      "Processing frame 2040...\n",
      "Triangulated 65 new map points.\n",
      "Processing frame 2050...\n",
      "Processing frame 2060...\n",
      "Processing frame 2070...\n",
      "Processing frame 2080...\n",
      "Processing frame 2090...\n",
      "Triangulated 14 new map points.\n",
      "Processing frame 2100...\n",
      "Triangulated 177 new map points.\n",
      "Processing frame 2110...\n",
      "Triangulated 63 new map points.\n",
      "Processing frame 2120...\n",
      "Triangulated 106 new map points.\n",
      "Processing frame 2130...\n",
      "Triangulated 91 new map points.\n",
      "Processing frame 2140...\n",
      "Triangulated 172 new map points.\n",
      "Processing frame 2150...\n",
      "Processing frame 2160...\n",
      "Processing frame 2170...\n",
      "Triangulated 63 new map points.\n",
      "Processing frame 2180...\n",
      "Triangulated 103 new map points.\n",
      "Processing frame 2190...\n",
      "Triangulated 1 new map points.\n",
      "Processing frame 2200...\n",
      "Processing frame 2210...\n",
      "Processing frame 2220...\n",
      "Processing frame 2230...\n",
      "Triangulated 26 new map points.\n",
      "Processing frame 2240...\n",
      "Triangulated 38 new map points.\n",
      "Processing frame 2250...\n",
      "Processing frame 2260...\n",
      "Processing frame 2270...\n",
      "Triangulated 7 new map points.\n",
      "Processing frame 2280...\n",
      "Processing frame 2290...\n",
      "Processing frame 2300...\n",
      "Triangulated 117 new map points.\n",
      "Processing frame 2310...\n",
      "Triangulated 143 new map points.\n",
      "Processing frame 2320...\n",
      "Triangulated 12 new map points.\n",
      "Processing frame 2330...\n",
      "Triangulated 85 new map points.\n",
      "Processing frame 2340...\n",
      "Triangulated 75 new map points.\n",
      "Processing frame 2350...\n",
      "Triangulated 26 new map points.\n",
      "Processing frame 2360...\n",
      "Triangulated 44 new map points.\n",
      "Processing frame 2370...\n",
      "Triangulated 179 new map points.\n",
      "Processing frame 2380...\n",
      "Triangulated 109 new map points.\n",
      "Processing frame 2390...\n",
      "Triangulated 163 new map points.\n",
      "Processing frame 2400...\n",
      "Triangulated 187 new map points.\n",
      "Processing frame 2410...\n",
      "Triangulated 185 new map points.\n",
      "Processing frame 2420...\n",
      "Triangulated 88 new map points.\n",
      "Processing frame 2430...\n",
      "Triangulated 171 new map points.\n",
      "Processing frame 2440...\n",
      "Processing frame 2450...\n",
      "Triangulated 77 new map points.\n",
      "Processing frame 2460...\n",
      "Triangulated 87 new map points.\n",
      "Processing frame 2470...\n",
      "Triangulated 171 new map points.\n",
      "Processing frame 2480...\n",
      "Triangulated 175 new map points.\n",
      "Processing finished. Close the Open3D window to exit.\n"
     ]
    }
   ],
   "source": [
    "slam_system = ORBSLAMSystem(camera_matrix, dist_coeffs)\n",
    "\n",
    "# --- Open3D Visualization Setup ---\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(window_name=\"ORB-SLAM (Conceptual with g2o-python)\", width=1280, height=720)\n",
    "mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])\n",
    "vis.add_geometry(mesh_frame)\n",
    "\n",
    "# Estimated Trajectory LineSet (will be updated)\n",
    "estimated_trajectory_line_set = o3d.geometry.LineSet()\n",
    "vis.add_geometry(estimated_trajectory_line_set)\n",
    "\n",
    "# Ground Truth Trajectory LineSet (will be updated)\n",
    "ground_truth_trajectory_line_set = o3d.geometry.LineSet()\n",
    "vis.add_geometry(ground_truth_trajectory_line_set)\n",
    "\n",
    "# Global Map Point Cloud (will be updated by the SLAM system)\n",
    "global_map_cloud_o3d = o3d.geometry.PointCloud()\n",
    "vis.add_geometry(global_map_cloud_o3d)\n",
    "\n",
    "\n",
    "view_control = vis.get_view_control()\n",
    "view_control.set_lookat([0, 0, 1])\n",
    "view_control.set_up([0, -1, 0])\n",
    "view_control.set_front([0, 0, -1])\n",
    "\n",
    "# Lists to store points for trajectory lines\n",
    "ground_truth_points = []\n",
    "estimated_points = []\n",
    "\n",
    "# --- Main Loop to Process Frames ---\n",
    "for i, (rgb_ts, rgb_file, depth_ts, depth_file) in enumerate(associations):\n",
    "    # Process every Nth frame for a quicker demo or all frames for full processing\n",
    "    if i % 5 == 0: # Process every 5th frame for more detail\n",
    "        print(f\"Processing frame {i}...\")\n",
    "\n",
    "        rgb_image, depth_image_meters = load_rgbd_frame(dataset_path, rgb_file, depth_file)\n",
    "\n",
    "        if rgb_image is not None and depth_image_meters is not None:\n",
    "            # --- Process frame with the SLAM system ---\n",
    "            estimated_pose_current_frame, current_map_cloud_from_slam = slam_system.process_frame(rgb_ts, rgb_image, depth_image_meters)\n",
    "\n",
    "            # --- Update Ground Truth Trajectory in visualization ---\n",
    "            closest_gt_ts = min(groundtruth_poses.keys(), key=lambda ts: abs(ts - rgb_ts))\n",
    "            if abs(closest_gt_ts - rgb_ts) < 0.05: # Threshold for association\n",
    "                gt_pose_data = groundtruth_poses[closest_gt_ts]\n",
    "                tx, ty, tz = gt_pose_data[0], gt_pose_data[1], gt_pose_data[2]\n",
    "                qx, qy, qz, qw = gt_pose_data[3], gt_pose_data[4], gt_pose_data[5], gt_pose_data[6]\n",
    "\n",
    "                R_gt = o3d.geometry.get_rotation_matrix_from_quaternion([qw, qx, qy, qz])\n",
    "                T_gt = np.eye(4)\n",
    "                T_gt[:3, :3] = R_gt\n",
    "                T_gt[:3, 3] = np.array([tx, ty, tz])\n",
    "\n",
    "                ground_truth_points.append(T_gt[:3, 3]) # Append position from ground truth\n",
    "                if len(ground_truth_points) > 1:\n",
    "                    gt_lines = [[len(ground_truth_points) - 2, len(ground_truth_points) - 1]]\n",
    "                    ground_truth_trajectory_line_set.points = o3d.utility.Vector3dVector(ground_truth_points)\n",
    "                    ground_truth_trajectory_line_set.lines = o3d.utility.Vector2iVector(gt_lines)\n",
    "                    ground_truth_trajectory_line_set.colors = o3d.utility.Vector3dVector([[1, 0, 0]]) # Red for ground truth\n",
    "                    vis.update_geometry(ground_truth_trajectory_line_set)\n",
    "\n",
    "\n",
    "            # --- Update Estimated Trajectory in visualization ---\n",
    "            estimated_points.append(estimated_pose_current_frame[:3, 3]) # Append position from estimated pose\n",
    "            if len(estimated_points) > 1:\n",
    "                est_lines = [[len(estimated_points) - 2, len(estimated_points) - 1]]\n",
    "                estimated_trajectory_line_set.points = o3d.utility.Vector3dVector(estimated_points)\n",
    "                estimated_trajectory_line_set.lines = o3d.utility.Vector2iVector(est_lines)\n",
    "                estimated_trajectory_line_set.colors = o3d.utility.Vector3dVector([[0, 0, 1]]) # Blue for estimated\n",
    "                vis.update_geometry(estimated_trajectory_line_set)\n",
    "\n",
    "            # --- Update Map Point Cloud in visualization ---\n",
    "            global_map_cloud_o3d.points = current_map_cloud_from_slam.points\n",
    "            global_map_cloud_o3d.colors = current_map_cloud_from_slam.colors\n",
    "            vis.update_geometry(global_map_cloud_o3d)\n",
    "\n",
    "\n",
    "            # --- Render the scene ---\n",
    "            vis.poll_events()\n",
    "            vis.update_renderer()\n",
    "            # time.sleep(0.01) # Optional: Add a small delay for smoother visualization\n",
    "        else:\n",
    "            print(f\"Skipping frame {i} due to image loading error.\")\n",
    "\n",
    "print(\"Processing finished. Close the Open3D window to exit.\")\n",
    "vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef3f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e711d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43ff7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
