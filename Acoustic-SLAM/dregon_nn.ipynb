{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile, loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DATASET_PATH = r\"DREGON/free-flight_whitenoise-high_room1\" \n",
    "\n",
    "# Base filename prefix (without extension)\n",
    "BASE_FILENAME = r\"DREGON_free-flight_whitenoise-high_room1\"\n",
    "\n",
    "NOISE_TEST_FILE = f\"{DATASET_PATH}/{BASE_FILENAME}.wav\"\n",
    "AUDIO_TS_MAT_FILE = f\"{DATASET_PATH}/{BASE_FILENAME}_audiots.mat\"\n",
    "# IMU_MAT_FILE = f\"{DATASET_PATH}/{BASE_FILENAME}_imu.mat\"\n",
    "SOURCE_POS_MAT_FILE = f\"{DATASET_PATH}/{BASE_FILENAME}_sourcepos.mat\"\n",
    "# MOTORS_MAT_FILE = f\"{DATASET_PATH}/{BASE_FILENAME}_motors.mat\" # Optional to load\n",
    "NOISE_TRAIN_FILE = r\"DREGON\\noise_training_room1.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbd451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "audio_ts_data = sio.loadmat(AUDIO_TS_MAT_FILE)['audio_timestamps']\n",
    "#imu_data = sio.loadmat(IMU_MAT_FILE)['imu'][0][0] #dtype=[('timestamps', 'O'), ('angular_velocity', 'O'), ('acceleration', 'O')]\n",
    "source_pos_data = sio.loadmat(SOURCE_POS_MAT_FILE)['source_position'][0][0] #dtype=[('timestamps', 'O'), ('azimuth', 'O'), ('elevation', 'O'), ('distance', 'O')]\n",
    "# motors_data = sio.loadmat(MOTORS_MAT_FILE)['motor'][0][0] #[('command', 'O'), ('measured', 'O'), ('timestamps', 'O')]\n",
    "\n",
    "# motors_data_r = motors_data.copy()\n",
    "# motors_data_r[0] = motors_data[2]\n",
    "# motors_data_r[1] = motors_data[0]\n",
    "# motors_data_r[2] = motors_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cdbe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 44100 Hz\n",
      "Audio Data Shape: (2668292, 8)\n",
      "Data Type: float32\n"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "\n",
    "sample_rate, audio_data = wav.read(NOISE_TEST_FILE)\n",
    "audio_data = audio_data.astype(np.float32)  \n",
    "print(f\"Sample Rate: {sample_rate} Hz\")\n",
    "print(f\"Audio Data Shape: {audio_data.shape}\")\n",
    "print(f\"Data Type: {audio_data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184a656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "fftSize_sec = 0.064\n",
    "freqRange = []\n",
    "micPos = np.asarray([  [0.0420  ,  0.0615   , -0.0410  ],# mic 1\n",
    "           [-0.0420,    0.0615,    0.0410],  # mic 2\n",
    "           [-0.0615,    0.0420,   -0.0410],  # mic 3\n",
    "           [-0.0615,   -0.0420,    0.0410],  # mic 4\n",
    "           [-0.0420,   -0.0615,   -0.0410],  # mic 5\n",
    "            [0.0420,   -0.0615,    0.0410],  # mic 6\n",
    "            [0.0615,   -0.0420,   -0.0410],  # mic 7\n",
    "\t\t\t[0.0615,    0.0420,    0.0410] ])# mic 8    \n",
    "subArray = np.asarray([0, 1, 2, 3, 4, 5, 6, 7]) # all mics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04793b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Resampled noisy signal shape: (968088, 8)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import resample_poly\n",
    "import os\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "noisy_signal = audio_data.copy() # Make a copy if you plan to modify it\n",
    "fs_true_noisy = sample_rate\n",
    "noisy_signal = noisy_signal.T\n",
    "max_vals = np.abs(noisy_signal).max(axis=1, keepdims=True)\n",
    "max_vals[max_vals == 0] = 1\n",
    "noisy_signal = noisy_signal / max_vals  \n",
    "\n",
    "resample_fs, fs = 16000, 44100\n",
    "resampled = np.array([\n",
    "    resample_poly(ch, resample_fs, fs) for ch in noisy_signal\n",
    "])\n",
    "\n",
    "resampled_noisy_signal = resampled.T\n",
    "\n",
    "print(f\"Resampled noisy signal shape: {resampled_noisy_signal.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f6dc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio timestamps shape: (968088,)\n"
     ]
    }
   ],
   "source": [
    "#resample timestamps\n",
    "n_samples = resampled_noisy_signal.shape[0]\n",
    "\n",
    "audio_ts = np.arange(n_samples)/resample_fs\n",
    "\n",
    "print(f\"Audio timestamps shape: {audio_ts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8eac1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled noise shape: (116080, 8)\n"
     ]
    }
   ],
   "source": [
    "noise_sample_rate, x_noise = wav.read(NOISE_TRAIN_FILE)\n",
    "x_noise = x_noise.astype(np.float32)  \n",
    "x_noise /= np.abs(x_noise).max()\n",
    "\n",
    "x_noise = x_noise.T\n",
    "\n",
    "fs_in = noise_sample_rate      # 44100 Hz\n",
    "fs_out = resample_fs           # 16000 Hz\n",
    "up, down = fs_out, fs_in\n",
    "\n",
    "x_noise_resample = np.array([\n",
    "    resample_poly(ch, up, down) for ch in x_noise\n",
    "])  # shape: (8, new_time)\n",
    "\n",
    "# Step 5: Subarray selection (if needed)\n",
    "\n",
    "x_noise_resample = x_noise_resample[subArray, :]\n",
    "x_noise_resample = x_noise_resample.T  # Transpose to shape (time, selected_channels)\n",
    "print(f\"Resampled noise shape: {x_noise_resample.shape}\")  # (selected_channels, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe84d9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source position data shape: azimuth (6246, 1), elevation (6246, 1), distance (6246, 1), timestamps (968088,)\n"
     ]
    }
   ],
   "source": [
    "s_az = source_pos_data['azimuth']\n",
    "s_el = source_pos_data['elevation']\n",
    "gt_timestamps = source_pos_data['timestamps'].flatten()\n",
    "s_dist = source_pos_data['distance']\n",
    "print(f\"Source position data shape: azimuth {s_az.shape}, elevation {s_el.shape}, distance {s_dist.shape}, timestamps {audio_ts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6e9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.signal import stft\n",
    "\n",
    "def compute_multichannel_spectrogram(audio, fs, fft_size=1024, hop_size=512):\n",
    "    \"\"\"\n",
    "    Convert multichannel waveform (shape: time x channels) into complex spectrogram\n",
    "    Returns: np.array of shape (channels, freq_bins, time_frames, 2) [real, imag]\n",
    "    \"\"\"\n",
    "    n_channels = audio.shape[1]\n",
    "    spec_list = []\n",
    "\n",
    "    for ch in range(n_channels):\n",
    "        f, t, Zxx = stft(audio[:, ch], fs=fs, nperseg=fft_size, noverlap=fft_size - hop_size)\n",
    "        spec = np.stack((np.real(Zxx), np.imag(Zxx)), axis=-1)  # shape: (freq_bins, time_frames, 2)\n",
    "        spec_list.append(spec)\n",
    "\n",
    "    spec_all = np.stack(spec_list, axis=0)  # shape: (channels, freq_bins, time_frames, 2)\n",
    "    return spec_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AudioDOANet(nn.Module):\n",
    "    def __init__(self, n_channels=8, input_shape=(256, 64), out_dim=3):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_channels * 2, 32, kernel_size=3, padding=1),  # *2 due to [real, imag]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, out_dim)  # azimuth, elevation, distance\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.cnn(x))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
